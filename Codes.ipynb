{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9947d81f-10d8-4cde-a560-a54a324575ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the characters from the each cell and saving it in each folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880f5d7-bd4e-4cfe-8299-dcc3c0d29916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def preprocess_sheet(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to smooth the image and reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Adaptive thresholding to binarize the image\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 8)\n",
    "    \n",
    "    # Invert the binary image to make characters black and background white\n",
    "    binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def extract_characters(binary_image, rows, cols, crop_percent=0.1):\n",
    "    # Get the dimensions of the binary image\n",
    "    height, width = binary_image.shape\n",
    "    \n",
    "    # Calculate the width and height of each cell in pixels\n",
    "    cell_width_pixels = width // cols\n",
    "    cell_height_pixels = height // rows\n",
    "    \n",
    "    # Calculate the number of pixels to crop from each side\n",
    "    crop_pixels_x = int(cell_width_pixels * crop_percent)\n",
    "    crop_pixels_y = int(cell_height_pixels * crop_percent)\n",
    "    \n",
    "    # Create a list to hold extracted characters\n",
    "    extracted_characters = []\n",
    "    \n",
    "    # Loop over each cell in the grid\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate the starting and ending coordinates of the cell\n",
    "            x_start = col * cell_width_pixels + crop_pixels_x\n",
    "            y_start = row * cell_height_pixels + crop_pixels_y\n",
    "            x_end = (col + 1) * cell_width_pixels - crop_pixels_x\n",
    "            y_end = (row + 1) * cell_height_pixels - crop_pixels_y\n",
    "            \n",
    "            # Ensure the coordinates are within image bounds\n",
    "            x_start = max(x_start, 0)\n",
    "            y_start = max(y_start, 0)\n",
    "            x_end = min(x_end, width)\n",
    "            y_end = min(y_end, height)\n",
    "            \n",
    "            # Extract the cell from the binary image\n",
    "            cell = binary_image[y_start:y_end, x_start:x_end]\n",
    "            \n",
    "            # Append the extracted cell to the list\n",
    "            extracted_characters.append(cell)\n",
    "\n",
    "    return extracted_characters\n",
    "\n",
    "def save_characters(characters, output_folder, sheet_index, rows, cols):\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Save each character in the corresponding folder\n",
    "    for index, character in enumerate(characters):\n",
    "        character_folder = os.path.join(output_folder, f'character_{index }')\n",
    "        if not os.path.exists(character_folder):\n",
    "            os.makedirs(character_folder)\n",
    "        \n",
    "        character_filename = f'{sheet_index + 1}.png'\n",
    "        character_path = os.path.join(character_folder, character_filename)\n",
    "        cv2.imwrite(character_path, character)\n",
    "\n",
    "def process_all_sheets(input_folder, output_folder, rows, cols):\n",
    "    # Check if input folder exists\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Input folder does not exist: {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    # List files in the input folder and print them for debugging\n",
    "    all_files = os.listdir(input_folder)\n",
    "    print(f\"Files in the input folder: {all_files}\")\n",
    "    \n",
    "    # Filter out .jpg files\n",
    "    sheet_files = sorted([f for f in all_files if f.lower().endswith('.jpg')])\n",
    "    \n",
    "    if not sheet_files:\n",
    "        print(f\"No .jpg files found in the input folder: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {len(sheet_files)} sheets from folder: {input_folder}\")\n",
    "\n",
    "    for sheet_index, sheet_file in enumerate(sheet_files):\n",
    "        sheet_path = os.path.join(input_folder, sheet_file)\n",
    "        \n",
    "        print(f\"Processing sheet: {sheet_path}\")\n",
    "        \n",
    "        # Preprocess the sheet to get the binarized image\n",
    "        binarized_image = preprocess_sheet(sheet_path)\n",
    "        \n",
    "        # Extract characters from the binarized image\n",
    "        characters = extract_characters(binarized_image, rows, cols)\n",
    "        \n",
    "        # Save the extracted characters to corresponding folders\n",
    "        save_characters(characters, output_folder, sheet_index, rows, cols)\n",
    "\n",
    "# Parameters\n",
    "input_folder = r'D:\\\\Tulu_lipi\\\\PROJECT'  # Folder containing the 112 images\n",
    "output_folder = r'D:\\\\Tulu_lipi\\\\Output'  # Folder where the extracted characters will be saved\n",
    "rows = 6\n",
    "cols = 9\n",
    "\n",
    "# Process all sheets\n",
    "process_all_sheets(input_folder, output_folder, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348ea169-df02-4d91-bd62-396f61c2b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc452ab-a674-49c6-990b-ee34ecf6a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def augment_images_with_slant(input_folder, output_folder, target_size=(150, 150)):\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for idx, file in enumerate(files):\n",
    "            input_path = os.path.join(root, file)\n",
    "            output_subfolder = os.path.relpath(root, input_folder)\n",
    "\n",
    "            # Ensure the output subfolder exists\n",
    "            output_subfolder_path = os.path.join(output_folder, output_subfolder)\n",
    "            os.makedirs(output_subfolder_path, exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                # Read the image\n",
    "                original_image = cv2.imread(input_path)\n",
    "\n",
    "                # Resize the image to the target size\n",
    "                resized_image = cv2.resize(original_image, target_size)\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Binarize the image and invert it\n",
    "                _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "                binary_image = cv2.bitwise_not(binary_image)\n",
    "\n",
    "                # Get image dimensions\n",
    "                height, width = binary_image.shape\n",
    "\n",
    "                # Define the slant angles for left and right\n",
    "                left_slant_angle = 10  # degrees\n",
    "                right_slant_angle = -10  # degrees\n",
    "\n",
    "                # Center of the image\n",
    "                center = (width // 2, height // 2)\n",
    "\n",
    "                # Compute the rotation matrices\n",
    "                left_rotation_matrix = cv2.getRotationMatrix2D(center, left_slant_angle, 1)\n",
    "                right_rotation_matrix = cv2.getRotationMatrix2D(center, right_slant_angle, 1)\n",
    "\n",
    "                # Apply the slant (rotation) transformations\n",
    "                left_slanted_image = cv2.warpAffine(binary_image, left_rotation_matrix, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,))\n",
    "                right_slanted_image = cv2.warpAffine(binary_image, right_rotation_matrix, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,))\n",
    "\n",
    "                # Save the original and slanted images\n",
    "                original_output_path = os.path.join(output_subfolder_path, f\"original_{idx}.png\")\n",
    "                left_slanted_output_path = os.path.join(output_subfolder_path, f\"left_slanted_{idx}.png\")\n",
    "                right_slanted_output_path = os.path.join(output_subfolder_path, f\"right_slanted_{idx}.png\")\n",
    "\n",
    "                cv2.imwrite(original_output_path, binary_image)\n",
    "                cv2.imwrite(left_slanted_output_path, left_slanted_image)\n",
    "                cv2.imwrite(right_slanted_output_path, right_slanted_image)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {input_path}: {e}\")\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    # Set your input folder and output folder for images\n",
    "    input_folder = 'D:\\\\Tulu_lipi\\\\Output'  # Change this to your input images folder path\n",
    "    output_folder = 'D:\\\\Tulu_lipi\\\\dataset'  # Change this to your output folder for augmented images\n",
    "\n",
    "    # Augment the images with left and right slants, and save the results\n",
    "    augment_images_with_slant(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cbc5d5-8052-432d-bafc-78bcff05e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tulu to kannada mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd1d04-3f7b-4309-b438-51662230fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the mapping from Tulu folder names to Kannada characters\n",
    "tulu_to_kannada_mapping = {\n",
    "    'character_1': 'ಅ',\n",
    "    'character_2': 'ಆ',\n",
    "    'character_3': 'ಇ',\n",
    "    'character_4': 'ಈ',\n",
    "    'character_5': 'ಉ',\n",
    "    'character_6': 'ಊ',\n",
    "    'character_7': 'ಋ',\n",
    "    'character_8': 'ೠ',\n",
    "    'character_9': 'ಎ',\n",
    "    'character_10': 'ಏ',\n",
    "    'character_11': 'ಐ',\n",
    "    'character_12': 'ಒ',\n",
    "    'character_13': 'ಔ',\n",
    "    'character_14': 'ಅಂ',\n",
    "    'character_15': 'ಅಃ',\n",
    "    'character_16': 'ಕ',\n",
    "    'character_17': 'ಖ',\n",
    "    'character_18': 'ಗ',\n",
    "    'character_19': 'ಘ',\n",
    "    'character_20': 'ಙ',\n",
    "    'character_21': 'ಚ',\n",
    "    'character_22': 'ಛ',\n",
    "    'character_23': 'ಜ',\n",
    "    'character_24': 'ಝ',\n",
    "    'character_25': 'ಞ',\n",
    "    'character_26': 'ಟ',\n",
    "    'character_27': 'ಠ',\n",
    "    'character_28': 'ಡ',\n",
    "    'character_29': 'ಢ',\n",
    "    'character_30': 'ಣ',\n",
    "    'character_31': 'ತ',\n",
    "    'character_32': 'ಥ',\n",
    "    'character_33': 'ದ',\n",
    "    'character_34': 'ಧ',\n",
    "    'character_35': 'ನ',\n",
    "    'character_36': 'ಪ',\n",
    "    'character_37': 'ಫ',\n",
    "    'character_38': 'ಬ',\n",
    "    'character_39': 'ಭ',\n",
    "    'character_40': 'ಮ',\n",
    "    'character_41': 'ಯ',\n",
    "    'character_42': 'ರ',\n",
    "    'character_43': 'ಲ',\n",
    "    'character_44': 'ವ',\n",
    "    'character_45': 'ಶ',\n",
    "    'character_46': 'ಷ',\n",
    "    'character_47': 'ಸ',\n",
    "    'character_48': 'ಹ',\n",
    "     'character_49': 'ಳ',\n",
    "    # Add mappings for remaining characters if there are more\n",
    "}\n",
    "\n",
    "# Path to the dataset\n",
    "tulu_characters_folder = \"D:\\\\Tulu_lipi\\\\dataset\"\n",
    "\n",
    "# Rename directories and images based on the mapping\n",
    "def rename_folders_and_images_to_kannada_characters(root_folder):\n",
    "    # Iterate through each folder in the root folder\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Get the Kannada character corresponding to the Tulu character folder_name\n",
    "            kannada_character = tulu_to_kannada_mapping.get(folder_name, 'Unknown')\n",
    "            \n",
    "            # New folder path\n",
    "            new_folder_path = os.path.join(root_folder, kannada_character)\n",
    "            os.rename(folder_path, new_folder_path)\n",
    "            \n",
    "            # Rename images inside the folder\n",
    "            for idx, image_name in enumerate(os.listdir(new_folder_path)):\n",
    "                image_path = os.path.join(new_folder_path, image_name)\n",
    "                if os.path.isfile(image_path):\n",
    "                    # Create the new image name with a unique identifier\n",
    "                    new_image_name = f\"{kannada_character}_{idx+1}{os.path.splitext(image_name)[1]}\"\n",
    "                    new_image_path = os.path.join(new_folder_path, new_image_name)\n",
    "                    os.rename(image_path, new_image_path)\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    # Rename the folders and images to Kannada characters based on the mappings\n",
    "    rename_folders_and_images_to_kannada_characters(tulu_characters_folder)\n",
    "    print(\"Folder and image renaming to Kannada characters completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1955007e-ba7e-4123-b4ac-ab3cfa9d0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30288eb2-cece-44f5-975f-088d7cb12e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image dimensions and paths\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "data_dir = 'D:\\\\Tulu_lipi\\\\dataset'\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # 20% of data for validation\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ac55a-44ca-4950-8b9f-30db77a3398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "num_classes=49\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5139a-8432-444a-b134-2f704c552bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(49, activation='softmax')  # 49 classes for 49 characters\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "model.save('tulu_character_recognition_model2.h5')\n",
    "val_loss, val_acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
